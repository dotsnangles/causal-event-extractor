{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "tokenizer = ElectraTokenizer.from_pretrained('tokenizer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['[PAD]', 'E_B', 'E_I', 'O']\n",
    "num_labels = len(labels)\n",
    "id2label = {k: v for k, v in enumerate(labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Preprocess for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data.tokens.apply(lambda x: ['[CLS]'] + x + ['[SEP]'])\n",
    "data['labels'] = data.labels.apply(lambda x: ['O'] + x + ['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tokens.apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data.tokens.apply(lambda x: x + ['[PAD]'] * (max_len - len(x)))\n",
    "data['labels'] = data.labels.apply(lambda x: x + ['[PAD]'] * (max_len - len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lst = data.tokens.to_list()\n",
    "labels_lst = data.labels.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(tokens_lst, \n",
    "                                                    labels_lst, \n",
    "                                                    test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for tokens, labels in zip(X_train, y_train):\n",
    "    length = tokens.index('[PAD]')\n",
    "    mask = [1] * length + [0] * (max_len - length)\n",
    "\n",
    "    label_ids = []\n",
    "    for label in labels:\n",
    "        label_ids.append(label2id[label])\n",
    "        \n",
    "    train_data.append([tokenizer.convert_tokens_to_ids(tokens), mask, label_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "for tokens, labels in zip(X_eval, y_eval):\n",
    "    length = tokens.index('[PAD]')\n",
    "    mask = [1] * length + [0] * (max_len - length)\n",
    "    \n",
    "    label_ids = []\n",
    "    for label in labels:\n",
    "        label_ids.append(label2id[label])\n",
    "        \n",
    "    eval_data.append([tokenizer.convert_tokens_to_ids(tokens), mask, label_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = random.randrange(0, len(train_data) - 1)\n",
    "# for x, xm, y in zip(train_data[idx][0], train_data[idx][1], train_data[idx][2]):\n",
    "#     print(x, xm, y)\n",
    "\n",
    "# idx = random.randrange(0, len(eval_data) - 1)\n",
    "# for x, xm, y in zip(eval_data[idx][0], eval_data[idx][1], eval_data[idx][2]):\n",
    "#     print(x, xm, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "LEARNING_RATE = 5e-5\n",
    "N_EPOCHS = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and Generate Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggerDataset(Dataset): \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.data[idx][0]\n",
    "        mask = self.data[idx][1]\n",
    "        label_ids = self.data[idx][2]\n",
    "        return (torch.LongTensor(input_ids), torch.LongTensor(mask), torch.LongTensor(label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TaggerDataset(train_data)\n",
    "eval_dataset = TaggerDataset(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTPoSTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 output_dim, \n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, mask):\n",
    "        embedded = self.dropout(self.bert(text, mask)[0])\n",
    "        predictions = self.fc(self.dropout(embedded))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(36223, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIM = num_labels\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTPoSTagger(bert,\n",
    "                      OUTPUT_DIM, \n",
    "                      DROPOUT)\n",
    "model.bert.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 0)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=0, factor=0.7, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NGPU = torch.cuda.device_count()\n",
    "if NGPU > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(NGPU)))\n",
    "    # model = torch.nn.DataParallel(model, device_ids=[0,1])\n",
    "    # torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = -1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = torch.nonzero(y != tag_pad_idx)\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_f1(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = -1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = torch.nonzero(y != tag_pad_idx)\n",
    "    max_preds_no_pad = max_preds[non_pad_elements].squeeze(1).detach().cpu()\n",
    "    y_no_pad = y[non_pad_elements].detach().cpu()\n",
    "    \n",
    "    f1_macro = f1_score(y_no_pad, max_preds_no_pad, average='macro')\n",
    "    f1_micro = f1_score(y_no_pad, max_preds_no_pad, average='micro')    \n",
    "    \n",
    "    return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    predictions_set = None\n",
    "    tags_set = None\n",
    "    for batch in iterator:\n",
    "        text = batch[0].to(device)\n",
    "        mask = batch[1].to(device)\n",
    "        tags = batch[2].to(device)\n",
    "\n",
    "        predictions = model(text, mask)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        if predictions_set == None:\n",
    "            predictions_set = predictions\n",
    "            tags_set = tags\n",
    "        else:\n",
    "            predictions_set = torch.cat([predictions_set, predictions], dim=0)\n",
    "            tags_set = torch.cat([tags_set, tags], dim=0)\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    f1_macro, f1_micro = categorical_f1(predictions_set, tags_set, tag_pad_idx)\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    predictions_set = None\n",
    "    tags_set = None\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].to(device)\n",
    "            mask = batch[1].to(device)\n",
    "            tags = batch[2].to(device)\n",
    "            \n",
    "            predictions = model(text, mask)\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            if predictions_set == None:\n",
    "                predictions_set = predictions\n",
    "                tags_set = tags\n",
    "            else:\n",
    "                predictions_set = torch.cat([predictions_set, predictions], dim=0)\n",
    "                tags_set = torch.cat([tags_set, tags], dim=0)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        f1_macro, f1_micro = categorical_f1(predictions_set, tags_set, tag_pad_idx)\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 34s\n",
      "Learning Rate: 5e-05\n",
      "\tTrain Loss: 0.856 | Train Acc: 0.69% | Train F1 Mac: 23.66% | Train F1 Mic: 68.35%\n",
      "\t Val. Loss: 0.646 |  Val. Acc: 0.78% |  Val. F1 Mac: 29.14% |  Val. F1 Mic: 77.65%\n",
      "\n",
      "Epoch: 02 | Epoch Time: 1m 13s\n",
      "Learning Rate: 5e-05\n",
      "\tTrain Loss: 0.622 | Train Acc: 0.77% | Train F1 Mac: 34.76% | Train F1 Mic: 77.15%\n",
      "\t Val. Loss: 0.474 |  Val. Acc: 0.81% |  Val. F1 Mac: 43.61% |  Val. F1 Mic: 81.14%\n",
      "\n",
      "Epoch: 03 | Epoch Time: 1m 12s\n",
      "Learning Rate: 5e-05\n",
      "\tTrain Loss: 0.427 | Train Acc: 0.83% | Train F1 Mac: 53.95% | Train F1 Mic: 82.63%\n",
      "\t Val. Loss: 0.320 |  Val. Acc: 0.87% |  Val. F1 Mac: 72.27% |  Val. F1 Mic: 87.42%\n",
      "\n",
      "Epoch: 04 | Epoch Time: 0m 43s\n",
      "Learning Rate: 5e-05\n",
      "\tTrain Loss: 0.284 | Train Acc: 0.89% | Train F1 Mac: 76.42% | Train F1 Mic: 88.91%\n",
      "\t Val. Loss: 0.236 |  Val. Acc: 0.91% |  Val. F1 Mac: 82.32% |  Val. F1 Mic: 91.30%\n",
      "\n",
      "Epoch: 05 | Epoch Time: 0m 42s\n",
      "Learning Rate: 5e-05\n",
      "\tTrain Loss: 0.215 | Train Acc: 0.92% | Train F1 Mac: 83.75% | Train F1 Mic: 92.07%\n",
      "\t Val. Loss: 0.218 |  Val. Acc: 0.92% |  Val. F1 Mac: 83.92% |  Val. F1 Mic: 91.68%\n",
      "\n",
      "Epoch: 06 | Epoch Time: 0m 42s\n",
      "Learning Rate: 3.5e-05\n",
      "\tTrain Loss: 0.174 | Train Acc: 0.94% | Train F1 Mac: 87.28% | Train F1 Mic: 93.72%\n",
      "\t Val. Loss: 0.237 |  Val. Acc: 0.91% |  Val. F1 Mac: 83.93% |  Val. F1 Mic: 91.09%\n",
      "\n",
      "Epoch: 07 | Epoch Time: 0m 42s\n",
      "Learning Rate: 3.5e-05\n",
      "\tTrain Loss: 0.144 | Train Acc: 0.95% | Train F1 Mac: 89.41% | Train F1 Mic: 94.88%\n",
      "\t Val. Loss: 0.196 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.59% |  Val. F1 Mic: 93.25%\n",
      "\n",
      "Epoch: 08 | Epoch Time: 0m 42s\n",
      "Learning Rate: 2.4499999999999996e-05\n",
      "\tTrain Loss: 0.124 | Train Acc: 0.96% | Train F1 Mac: 90.92% | Train F1 Mic: 95.72%\n",
      "\t Val. Loss: 0.202 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.56% |  Val. F1 Mic: 93.33%\n",
      "\n",
      "Epoch: 09 | Epoch Time: 0m 42s\n",
      "Learning Rate: 1.7149999999999997e-05\n",
      "\tTrain Loss: 0.108 | Train Acc: 0.96% | Train F1 Mac: 92.06% | Train F1 Mic: 96.32%\n",
      "\t Val. Loss: 0.208 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.68% |  Val. F1 Mic: 93.22%\n",
      "\n",
      "Epoch: 10 | Epoch Time: 0m 42s\n",
      "Learning Rate: 1.2004999999999998e-05\n",
      "\tTrain Loss: 0.096 | Train Acc: 0.97% | Train F1 Mac: 93.17% | Train F1 Mic: 96.84%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.46% |  Val. F1 Mic: 93.10%\n",
      "\n",
      "Epoch: 11 | Epoch Time: 1m 8s\n",
      "Learning Rate: 8.403499999999998e-06\n",
      "\tTrain Loss: 0.089 | Train Acc: 0.97% | Train F1 Mac: 93.62% | Train F1 Mic: 97.11%\n",
      "\t Val. Loss: 0.226 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.51% |  Val. F1 Mic: 93.03%\n",
      "\n",
      "Epoch: 12 | Epoch Time: 1m 19s\n",
      "Learning Rate: 5.882449999999998e-06\n",
      "\tTrain Loss: 0.083 | Train Acc: 0.97% | Train F1 Mac: 93.96% | Train F1 Mic: 97.26%\n",
      "\t Val. Loss: 0.221 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.69% |  Val. F1 Mic: 93.32%\n",
      "\n",
      "Epoch: 13 | Epoch Time: 1m 15s\n",
      "Learning Rate: 4.117714999999998e-06\n",
      "\tTrain Loss: 0.083 | Train Acc: 0.97% | Train F1 Mac: 94.20% | Train F1 Mic: 97.38%\n",
      "\t Val. Loss: 0.229 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.69% |  Val. F1 Mic: 93.30%\n",
      "\n",
      "Epoch: 14 | Epoch Time: 1m 17s\n",
      "Learning Rate: 2.8824004999999986e-06\n",
      "\tTrain Loss: 0.083 | Train Acc: 0.97% | Train F1 Mac: 94.07% | Train F1 Mic: 97.33%\n",
      "\t Val. Loss: 0.228 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.76% |  Val. F1 Mic: 93.34%\n",
      "\n",
      "Epoch: 15 | Epoch Time: 1m 16s\n",
      "Learning Rate: 2.017680349999999e-06\n",
      "\tTrain Loss: 0.081 | Train Acc: 0.97% | Train F1 Mac: 94.33% | Train F1 Mic: 97.47%\n",
      "\t Val. Loss: 0.231 |  Val. Acc: 0.93% |  Val. F1 Mac: 86.60% |  Val. F1 Mic: 93.19%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m      7\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_acc, train_f1_mac, train_f1_mic \u001b[39m=\u001b[39m train(model, train_loader, optimizer, criterion, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     valid_loss, valid_acc, valid_f1_mac, valid_f1_mic \u001b[39m=\u001b[39m evaluate(model, eval_loader, criterion, \u001b[39m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(valid_loss)\n",
      "Cell \u001b[0;32mIn [24], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, tag_pad_idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m acc \u001b[39m=\u001b[39m categorical_accuracy(predictions, tags, tag_pad_idx)\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     28\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/tensor.py:221\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Tensor \u001b[39mand\u001b[39;00m has_torch_function(relevant_args):\n\u001b[1;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    215\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    216\u001b[0m         relevant_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m         retain_graph\u001b[39m=\u001b[39mretain_graph,\n\u001b[1;32m    220\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph)\n\u001b[0;32m--> 221\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/autograd/__init__.py:130\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 130\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    131\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph,\n\u001b[1;32m    132\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_f1_mac, train_f1_mic = train(model, train_loader, optimizer, criterion, 0)\n",
    "    valid_loss, valid_acc, valid_f1_mac, valid_f1_mic = evaluate(model, eval_loader, criterion, 0)\n",
    "    \n",
    "    cur_lr = scheduler.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    scheduler.step(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'event_tagger.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'Learning Rate: {cur_lr}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%', end=' | ')\n",
    "    print(f'Train F1 Mac: {train_f1_mac*100:.2f}% | Train F1 Mic: {train_f1_mic*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%', end=' |  ')\n",
    "    print(f'Val. F1 Mac: {valid_f1_mac*100:.2f}% |  Val. F1 Mic: {valid_f1_mic*100:.2f}%', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeonghyeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
